# -*- coding: utf-8 -*-
"""yolo_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15w90pBgh73ekL5zPcCvuR3AJfR_FCGBx
"""

!pip install ultralytics

from google.colab import drive
drive.mount('/content/drive')

# ----------------------------
# Libraries
import os
import random
import numpy as np
import torch
import torch.nn as nn
from torchvision.models import mobilenet_v2
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, TensorDataset
import cv2
from PIL import Image
from ultralytics import YOLO
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from google.colab.patches import cv2_imshow

# ----------------------------
# Paths and labels
data_path = '/content/drive/MyDrive/Yolo_model/archive/files'
labels = ['aggressive','non_aggressive']
num_classes = len(labels)

# ----------------------------
# Transform and Sharp Filter
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
 #   transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])


# ----------------------------
# Load videos and preprocess frames
X, y = [], []

for idx, cls in enumerate(labels):
    cls_dir = os.path.join(data_path, cls)
    videos = os.listdir(cls_dir)

    for vid in videos:
        vid_path = os.path.join(cls_dir, vid)
        cap = cv2.VideoCapture(vid_path)

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # Process every frame
            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(img)
            img = transform(img)
            X.append(img)
            y.append(idx)

        cap.release()

X = torch.stack(X)
y = torch.tensor(y)
# ----------------------------
# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
train_ds = TensorDataset(X_train, y_train)
test_ds = TensorDataset(X_test, y_test)
train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)
test_dl = DataLoader(test_ds, batch_size=32)

# ----------------------------
# YOLO + MobileNetV2 Model
class YOLO_MobileNetV2(nn.Module):
    def __init__(self, num_classes=num_classes, yolo_weights='yolov8x.pt', mobilenet_weights=None):
        super().__init__()
        self.yolo = YOLO(yolo_weights)
        self.mobilenet = mobilenet_v2(pretrained=True)
        self.mobilenet.classifier = nn.Sequential(
            nn.Linear(self.mobilenet.classifier[1].in_features, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512,num_classes)

        )
        if mobilenet_weights:
            self.mobilenet.load_state_dict(torch.load(mobilenet_weights, map_location="cpu"))

    def forward(self, frame):
        results = self.yolo(frame)
        output = []

        for box in results[0].boxes:
            if int(box.cls) == 0:  # person class
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                crop = frame[y1:y2, x1:x2]
                crop = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)
                crop = Image.fromarray(crop)
                crop = transform(crop).unsqueeze(0)

                with torch.no_grad():
                    pred = self.mobilenet(crop)
                    label_idx = torch.argmax(pred, 1).item()

                output.append({
                    "bbox": (x1, y1, x2, y2),
                    "label": label_idx
                })
        return output

# ----------------------------
# Initialize model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = YOLO_MobileNetV2()
model.mobilenet.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.mobilenet.parameters(), lr=1e-5)

# ----------------------------
# Training with EarlyStopping
num_epochs = 50
patience = 5
best_val_loss = float('inf')

train_losses, val_losses, train_accs, val_accs = [], [], [], []

for epoch in range(num_epochs):
    model.mobilenet.train()
    running_loss, correct, total = 0, 0, 0

    for xb, yb in train_dl:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        preds = model.mobilenet(xb)
        loss = criterion(preds, yb)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        correct += (preds.argmax(1) == yb).sum().item()
        total += yb.size(0)

    train_loss = running_loss / len(train_dl)
    train_acc = correct / total
    train_losses.append(train_loss)
    train_accs.append(train_acc)

    # Validation
    model.mobilenet.eval()
    val_loss, val_correct, val_total = 0, 0, 0
    with torch.no_grad():
        for xb, yb in test_dl:
            xb, yb = xb.to(device), yb.to(device)
            preds = model.mobilenet(xb)
            loss = criterion(preds, yb)
            val_loss += loss.item()
            val_correct += (preds.argmax(1) == yb).sum().item()
            val_total += yb.size(0)

    val_loss /= len(test_dl)
    val_acc = val_correct / val_total
    val_losses.append(val_loss)
    val_accs.append(val_acc)

    print(f"Epoch {epoch+1} | Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")

    # Early Stopping
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        epochs_no_improve = 0
        torch.save(model.mobilenet.state_dict(), "best_mobilenet.pt")
    else:
        epochs_no_improve += 1
        if epochs_no_improve >= patience:
            print(f"Early stopping at epoch {epoch+1}")
            break

# Load best model
model.mobilenet.load_state_dict(torch.load("best_mobilenet.pt"))

# ----------------------------
# Plot training curves
plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Val Loss")
plt.legend()
plt.show()

plt.plot(train_accs, label="Train Accuracy")
plt.plot(val_accs, label="Val Accuracy")
plt.legend()
plt.show()

# ----------------------------
# Classification Report
all_preds, all_labels = [], []
model.mobilenet.eval()
with torch.no_grad():
    for xb, yb in test_dl:
        xb = xb.to(device)
        preds = model.mobilenet(xb)
        all_preds.extend(preds.argmax(1).cpu().numpy())
        all_labels.extend(yb.cpu().numpy())

print(classification_report(all_labels, all_preds, target_names=labels))

# ----------------------------
# Inference + Collect Frames to Video
all_videos = [os.path.join(data_path, cls, vid) for cls in labels for vid in os.listdir(os.path.join(data_path, cls))]
random_video = random.choice(all_videos)
print("Random video:", random_video)

cap = cv2.VideoCapture(random_video)
model.mobilenet.eval()

# Video writer
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out_video = cv2.VideoWriter('output_video.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))

while True:
    ret, frame = cap.read()
    if not ret:
        break

    output = model.forward(frame)

    # Draw bounding boxes and labels
    for obj in output:
        x1, y1, x2, y2 = obj["bbox"]
        label_idx = obj["label"]
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)
        cv2.putText(frame, labels[label_idx], (x1, y1-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)

    cv2_imshow(frame)  # show frame in Colab
    out_video.write(frame)  # add frame to video

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
out_video.release()
cv2.destroyAllWindows()
print("Video saved as output_video.mp4")
save_path = '/content/drive/MyDrive/OCR_project/Yolo_model1/best_mobilenet.pt'
torch.save(model.mobilenet.state_dict(), save_path)

!pip install ultralytics

from google.colab import drive
drive.mount('/content/drive')

# ----------------------------
# Libraries
import os
import random
import numpy as np
import torch
import torch.nn as nn
from torchvision.models import mobilenet_v2
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, TensorDataset
import cv2
from PIL import Image
from ultralytics import YOLO
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from google.colab.patches import cv2_imshow

# ----------------------------
# Paths and labels
data_path = '/content/drive/MyDrive/Yolo_model/archive/files'
labels = ['aggressive','non_aggressive']
num_classes = len(labels)

# ----------------------------
# Transform and Sharp Filter
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
 #   transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])


# ----------------------------
# Load videos and preprocess frames
X, y = [], []

for idx, cls in enumerate(labels):
    cls_dir = os.path.join(data_path, cls)
    videos = os.listdir(cls_dir)

    for vid in videos:
        vid_path = os.path.join(cls_dir, vid)
        cap = cv2.VideoCapture(vid_path)

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # Process every frame
            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(img)
            img = transform(img)
            X.append(img)
            y.append(idx)

        cap.release()

X = torch.stack(X)
y = torch.tensor(y)
# ----------------------------
# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
train_ds = TensorDataset(X_train, y_train)
test_ds = TensorDataset(X_test, y_test)
train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)
test_dl = DataLoader(test_ds, batch_size=32)

# ----------------------------
# YOLO + MobileNetV2 Model
class YOLO_MobileNetV2(nn.Module):
    def __init__(self, num_classes=num_classes, yolo_weights='yolov8x.pt', mobilenet_weights=None):
        super().__init__()
        self.yolo = YOLO(yolo_weights)
        self.mobilenet = mobilenet_v2(pretrained=True)
        self.mobilenet.classifier = nn.Sequential(
          nn.Linear(self.mobilenet.classifier[1].in_features, 1080),
          nn.ReLU(),
          nn.Dropout(0.3),
          nn.Linear(1080, 512),
          nn.ReLU(),
          nn.Dropout(0.3),
          nn.Linear(512, 2)
)
        if mobilenet_weights:
            self.mobilenet.load_state_dict(torch.load(mobilenet_weights, map_location="cpu"))

    def forward(self, frame):
        results = self.yolo(frame)
        output = []

        for box in results[0].boxes:
            if int(box.cls) == 0:  # person class
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                crop = frame[y1:y2, x1:x2]
                crop = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)
                crop = Image.fromarray(crop)
                crop = transform(crop).unsqueeze(0)

                with torch.no_grad():
                    pred = self.mobilenet(crop)
                    label_idx = torch.argmax(pred, 1).item()

                output.append({
                    "bbox": (x1, y1, x2, y2),
                    "label": label_idx
                })
        return output

# ----------------------------
# Initialize model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = YOLO_MobileNetV2()
model.mobilenet.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.mobilenet.parameters(), lr=1e-5)

# ----------------------------
# Training with EarlyStopping
num_epochs = 50
patience = 5
best_val_loss = float('inf')

train_losses, val_losses, train_accs, val_accs = [], [], [], []

for epoch in range(num_epochs):
    model.mobilenet.train()
    running_loss, correct, total = 0, 0, 0

    for xb, yb in train_dl:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        preds = model.mobilenet(xb)
        loss = criterion(preds, yb)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        correct += (preds.argmax(1) == yb).sum().item()
        total += yb.size(0)

    train_loss = running_loss / len(train_dl)
    train_acc = correct / total
    train_losses.append(train_loss)
    train_accs.append(train_acc)

    # Validation
    model.mobilenet.eval()
    val_loss, val_correct, val_total = 0, 0, 0
    with torch.no_grad():
        for xb, yb in test_dl:
            xb, yb = xb.to(device), yb.to(device)
            preds = model.mobilenet(xb)
            loss = criterion(preds, yb)
            val_loss += loss.item()
            val_correct += (preds.argmax(1) == yb).sum().item()
            val_total += yb.size(0)

    val_loss /= len(test_dl)
    val_acc = val_correct / val_total
    val_losses.append(val_loss)
    val_accs.append(val_acc)

    print(f"Epoch {epoch+1} | Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")

    # Early Stopping
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        epochs_no_improve = 0
        torch.save(model.mobilenet.state_dict(), "best_mobilenet.pt")
    else:
        epochs_no_improve += 1
        if epochs_no_improve >= patience:
            print(f"Early stopping at epoch {epoch+1}")
            break

# Load best model
model.mobilenet.load_state_dict(torch.load("best_mobilenet.pt"))

# ----------------------------
# Plot training curves
plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Val Loss")
plt.legend()
plt.show()

plt.plot(train_accs, label="Train Accuracy")
plt.plot(val_accs, label="Val Accuracy")
plt.legend()
plt.show()

# ----------------------------
# Classification Report
all_preds, all_labels = [], []
model.mobilenet.eval()
with torch.no_grad():
    for xb, yb in test_dl:
        xb = xb.to(device)
        preds = model.mobilenet(xb)
        all_preds.extend(preds.argmax(1).cpu().numpy())
        all_labels.extend(yb.cpu().numpy())

print(classification_report(all_labels, all_preds, target_names=labels))

# ----------------------------
# Inference + Collect Frames to Video
all_videos = [os.path.join(data_path, cls, vid) for cls in labels for vid in os.listdir(os.path.join(data_path, cls))]
random_video = random.choice(all_videos)
print("Random video:", random_video)

cap = cv2.VideoCapture(random_video)
model.mobilenet.eval()

# Video writer
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out_video = cv2.VideoWriter('output_video.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))

while True:
    ret, frame = cap.read()
    if not ret:
        break

    output = model.forward(frame)

    # Draw bounding boxes and labels
    for obj in output:
        x1, y1, x2, y2 = obj["bbox"]
        label_idx = obj["label"]
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)
        cv2.putText(frame, labels[label_idx], (x1, y1-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)

    cv2_imshow(frame)  # show frame in Colab
    out_video.write(frame)  # add frame to video

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
out_video.release()
cv2.destroyAllWindows()
print("Video saved as output_video1080.mp4")
save_path = '/content/drive/MyDrive/OCR_project/Yolo_model1/best_mobilenet2.pt'
torch.save(model.mobilenet.state_dict(), save_path)

